{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "def tryfloat(value):\n",
      "    if (value.strip() == 'NA') or (value.strip() == \"\"):\n",
      "        return np.NaN\n",
      "    try:\n",
      "        return float(value)\n",
      "    except ValueError:\n",
      "        return value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 282
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import glob\n",
      "\n",
      "relevant_rsids = {'rs7279445', 'rs5760410', 'rs1801394', 'rs13120400', 'rs4673993', 'rs548234'}\n",
      "\n",
      "patients = list()\n",
      "drug_response_data = list()\n",
      "\n",
      "# Load clinical data\n",
      "line_number = 1\n",
      "#for line in open('rheumatoid-arthritis/raw_final/TestData_Cov_Release.txt'):\n",
      "for line in open('rheumatoid-arthritis/raw_training/TrainingData_PhenoCov_Release.txt'):\n",
      "    if line_number == 1: \n",
      "        column_names = line.strip().split(' ') \n",
      "    else:\n",
      "        patient_data = dict(zip(column_names, line.strip().split(' '))) # column_name: value\n",
      "        if patient_data['Drug'] == 'NA':\n",
      "            \n",
      "        if 'Response.NonResp' in patient_data:\n",
      "            if patient_data['Response.NonResp'] == '1':\n",
      "                drug_response_data.append(1)\n",
      "            elif patient_data['Response.NonResp'] == '0':\n",
      "                drug_response_data.append(-1)\n",
      "            else:\n",
      "                drug_response_data.append(patient_data['Response.NonResp'])\n",
      "        \n",
      "        # filter values to only contain relevant information for training/using the classifier\n",
      "        patient_data = { key: tryfloat(patient_data[key]) for key in {'Mtx', 'Drug', 'baselineDAS', 'Gender'}}\n",
      "        patients.append(patient_data)\n",
      "    line_number += 1\n",
      "    \n",
      "if len(patients) != len(drug_response_data):\n",
      "    print('Error: length of patient data list does not equal length of drug response data list.')\n",
      "\n",
      "# Load dosage data\n",
      "# for file_name in glob.glob('rheumatoid-arthritis/raw_final/*.dos'):\n",
      "for file_name in glob.glob('rheumatoid-arthritis/raw_training/*.dos'):\n",
      "    print('Loading', file_name)\n",
      "    with open(file_name) as f:\n",
      "        for line in f:\n",
      "            i += 1\n",
      "            for rsid in relevant_rsids:\n",
      "                if rsid in line:\n",
      "                    genetic_data_line = line.strip().split(' ')\n",
      "                    rsid = genetic_data_line[1]\n",
      "                    dosage_data = genetic_data_line[6:]\n",
      "                    if len(dosage_data) == len(patients):\n",
      "                        for i, dosage in enumerate(dosage_data):\n",
      "                            patients[i][rsid] = tryfloat(dosage)\n",
      "                    else:\n",
      "                        print('Error: number of SNP variants found (' + str(len(dosage_data)) + ') does not equal number of patients (' + str(len(patients)) + ')')\n",
      "print('Finished loading.')\n",
      "\n",
      "for patient in patients:\n",
      "    patient['methotroxate_score'] = patient['Mtx'] * (patient['rs4673993'] + patient['rs7279445'] + patient['rs1801394'] + patient['rs5760410'])\n",
      "\n",
      "# Filter out patients with unknown drug response\n",
      "index_of_first_NA_item = drug_response_data.index('NA')\n",
      "drug_response_data = drug_response_data[0:index_of_first_NA_item]\n",
      "patients = patients[0:index_of_first_NA_item]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading rheumatoid-arthritis/raw_training\\Training_chr2.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_training\\Training_chr21.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_training\\Training_chr22.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_training\\Training_chr4.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_training\\Training_chr5.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_training\\Training_chr6.dos\n",
        "Finished loading."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 289
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction import DictVectorizer\n",
      "from sklearn.preprocessing import Imputer\n",
      "\n",
      "# convert data dictionary to matrix\n",
      "vec = DictVectorizer()\n",
      "patients_vectorized = vec.fit_transform(patients).toarray()\n",
      "\n",
      "# take care of NaNs\n",
      "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
      "imp.fit(patients_vectorized)\n",
      "patients_vectorized = imp.transform(patients_vectorized)\n",
      "\n",
      "print(\"Features:\\n\")\n",
      "print(vec.get_feature_names())\n",
      "print(\"\\nExample data matrices:\\n\")\n",
      "print(patients_vectorized[0:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Features:\n",
        "\n",
        "['Drug', 'Drug=adalimumab', 'Drug=etanercept', 'Drug=infliximab', 'Gender', 'Mtx', 'baselineDAS', 'methotroxate_score', 'rs13120400', 'rs1801394', 'rs4673993', 'rs548234', 'rs5760410', 'rs7279445']\n",
        "\n",
        "Example data matrices:\n",
        "\n",
        "[[ 0.    0.    0.    1.    0.    1.    3.18  2.6   2.    0.    2.    0.36\n",
        "   0.6   0.  ]\n",
        " [ 0.    0.    0.    1.    1.    1.    4.65  4.26  0.    2.    0.    0.    1.\n",
        "   1.26]\n",
        " [ 0.    0.    1.    0.    1.    1.    4.38  5.89  1.44  1.    2.    0.    1.\n",
        "   1.89]\n",
        " [ 0.    0.    0.    1.    1.    1.    2.45  2.43  1.    0.    0.    0.\n",
        "   0.47  1.96]\n",
        " [ 0.    0.    0.    1.    1.    0.    3.87  0.    0.01  1.95  1.    1.\n",
        "   0.11  1.87]]\n"
       ]
      }
     ],
     "prompt_number": 291
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.datasets import make_moons, make_circles, make_classification\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn import tree\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.qda import QDA\n",
      "from sklearn.dummy import DummyClassifier\n",
      "from sklearn import metrics\n",
      "from sklearn.metrics import log_loss as sklearn_log_loss\n",
      "from sklearn import cross_validation\n",
      "\n",
      "patients_vectorized_train, patients_vectorized_test, drug_response_data_train, drug_response_data_test = cross_validation.train_test_split(\n",
      "        patients_vectorized, drug_response_data, test_size=0.2, random_state=3)\n",
      "\n",
      "classifiers = [(\"DUMMY classifier - stratified\", DummyClassifier(strategy = 'stratified')),\n",
      "               (\"DUMMY classifier - most frequent\", DummyClassifier(strategy = 'most_frequent')),\n",
      "               (\"DUMMY classifier - uniform random\", DummyClassifier(strategy = 'uniform')),\n",
      "               (\"Nearest Neighbors\", KNeighborsClassifier(20)), \n",
      "               (\"Linear SVM\", SVC(kernel=\"linear\", C=0.025, probability = True)),\n",
      "               (\"RBF SVM\", SVC(gamma=1, C=1, probability = True)),\n",
      "               (\"RBF SVM 2\", SVC(gamma=1000, C=10, probability = True)),\n",
      "               (\"Stochastic Gradient Descent\", SGDClassifier(loss=\"log\", penalty=\"l2\")),\n",
      "               (\"Decision Tree\", DecisionTreeClassifier(max_depth=5)),\n",
      "               (\"Decision Tree 2\", DecisionTreeClassifier(max_depth=1)),\n",
      "               (\"Random Forest\", RandomForestClassifier(max_depth=4, n_estimators=10, max_features=5)),\n",
      "               (\"Extremeley Randomized Trees\", ExtraTreesClassifier(n_estimators=10, max_depth=2, min_samples_split=1, random_state=0)),\n",
      "               (\"Gradient Boosting Classifier\", GradientBoostingClassifier(n_estimators=50, learning_rate=.5, max_depth=1, random_state=0)),\n",
      "               (\"AdaBoost\", AdaBoostClassifier()),\n",
      "               (\"Naive Bayes\", GaussianNB()),\n",
      "               (\"LDA\", LDA())]\n",
      "\n",
      "\n",
      "for name, clf in classifiers:\n",
      "    clf.fit(patients_vectorized_train, drug_response_data_train)\n",
      "    score = clf.score(patients_vectorized_test, drug_response_data_test)\n",
      "    clf_predict_proba = clf.predict_proba(patients_vectorized_test)\n",
      "    log_loss = sklearn_log_loss(drug_response_data_test, clf.predict_proba(patients_vectorized_test))\n",
      "    print(name, 'score:', '{0:.3f}'.format(score),  'log loss:', '{0:.3f}'.format(log_loss))\n",
      "    scores = cross_validation.cross_val_score(clf, patients_vectorized_test, drug_response_data_test, cv=5, scoring='roc_auc')\n",
      "    print(\"ROC AUC: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
      "    scores = cross_validation.cross_val_score(clf, patients_vectorized_test, drug_response_data_test, cv=5, scoring='accuracy')\n",
      "    print(\"accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
      "    scores = cross_validation.cross_val_score(clf, patients_vectorized_test, drug_response_data_test, cv=5, scoring='log_loss')\n",
      "    print(\"log loss: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
      "    scores = cross_validation.cross_val_score(clf, patients_vectorized_test, drug_response_data_test, cv=5, scoring='f1')\n",
      "    print(\"F1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DUMMY classifier - stratified score: 0.654 log loss: 12.050\n",
        "ROC AUC: 0.52 (+/- 0.03)\n",
        "accuracy: 0.63 (+/- 0.09)\n",
        "log loss: -13.07 (+/- 1.50)\n",
        "F1: 0.22 (+/- 0.17)\n",
        "\n",
        "DUMMY classifier - most frequent score: 0.759 log loss: 8.316\n",
        "ROC AUC: 0.50 (+/- 0.00)\n",
        "accuracy: 0.76 (+/- 0.01)\n",
        "log loss: -8.32 (+/- 0.36)\n",
        "F1: 0.00 (+/- 0.00)\n",
        "\n",
        "DUMMY classifier - uniform random score: 0.455 log loss: 0.693\n",
        "ROC AUC: 0.50 (+/- 0.00)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.54 (+/- 0.10)\n",
        "log loss: -0.69 (+/- 0.00)\n",
        "F1: 0.32 (+/- 0.11)\n",
        "\n",
        "Nearest Neighbors"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " score: 0.759 log loss: 0.873\n",
        "ROC AUC: 0.55 (+/- 0.23)\n",
        "accuracy: 0.76 (+/- 0.01)\n",
        "log loss: -0.56 (+/- 0.08)\n",
        "F1: 0.04 (+/- 0.09)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Linear SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " score: 0.759 log loss: 0.625\n",
        "ROC AUC: 0.58 (+/- 0.14)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.76 (+/- 0.01)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "log loss: -0.55 (+/- 0.02)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1: 0.00 (+/- 0.00)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "RBF SVM"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " score: 0.754 log loss: 0.551\n",
        "ROC AUC: 0.53 (+/- 0.20)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.76 (+/- 0.02)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "log loss: -0.57 (+/- 0.04)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1: 0.00 (+/- 0.00)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "RBF SVM 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " score: 0.759 log loss: 0.555\n",
        "ROC AUC: 0.50 (+/- 0.01)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.76 (+/- 0.01)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "log loss: -0.55 (+/- 0.01)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1: 0.00 (+/- 0.00)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Stochastic Gradient Descent score: 0.717 log loss: 6.103\n",
        "ROC AUC: 0.61 (+/- 0.18)\n",
        "accuracy: 0.56 (+/- 0.37)\n",
        "log loss: -12.57 (+/- 12.81)\n",
        "F1: 0.40 (+/- 0.15)\n",
        "\n",
        "Decision Tree score: 0.744 log loss: 0.743\n",
        "ROC AUC: 0.55 (+/- 0.14)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.77 (+/- 0.04)\n",
        "log loss: -2.25 (+/- 2.07)\n",
        "F1: 0.31 (+/- 0.17)\n",
        "\n",
        "Decision Tree 2 score: 0.759 log loss: 0.519\n",
        "ROC AUC: 0.61 (+/- 0.08)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.79 (+/- 0.04)\n",
        "log loss: -0.51 (+/- 0.05)\n",
        "F1: 0.37 (+/- 0.20)\n",
        "\n",
        "Random Forest score: 0.762 log loss: 0.531\n",
        "ROC AUC: 0.65 (+/- 0.08)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.77 (+/- 0.04)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "log loss: -0.53 (+/- 0.07)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1: 0.17 (+/- 0.16)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Extremeley Randomized Trees score: 0.759 log loss: 0.555\n",
        "ROC AUC: 0.51 (+/- 0.14)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.76 (+/- 0.01)\n",
        "log loss: -0.55 (+/- 0.02)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1: 0.00 (+/- 0.00)\n",
        "\n",
        "Gradient Boosting Classifier"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " score: 0.767 log loss: 0.539\n",
        "ROC AUC: 0.64 (+/- 0.09)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.78 (+/- 0.03)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "log loss: -0.52 (+/- 0.04)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1: 0.33 (+/- 0.19)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "AdaBoost"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " score: 0.759 log loss: 0.683\n",
        "ROC AUC: 0.61 (+/- 0.06)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.77 (+/- 0.05)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "log loss: -0.68 (+/- 0.00)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1: 0.34 (+/- 0.26)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Naive Bayes score: 0.769 log loss: 0.575\n",
        "ROC AUC: 0.58 (+/- 0.17)\n",
        "accuracy: 0.78 (+/- 0.05)\n",
        "log loss: -0.55 (+/- 0.09)\n",
        "F1: 0.26 (+/- 0.23)\n",
        "\n",
        "LDA score: 0.757 log loss: 0.564\n",
        "ROC AUC: 0.62 (+/- 0.19)\n",
        "accuracy: 0.77 (+/- 0.05)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "log loss: -0.54 (+/- 0.08)\n",
        "F1: 0.21 (+/- 0.25)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 292
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = GradientBoostingClassifier(n_estimators=50, learning_rate=.5, max_depth=1, random_state=0)\n",
      "\n",
      "clf.fit(patients_vectorized, drug_response_data)\n",
      "score = clf.score(patients_vectorized, drug_response_data)\n",
      "log_loss = sklearn_log_loss(drug_response_data, clf.predict_proba(patients_vectorized))\n",
      "\n",
      "print('score:', '{0:.3f}'.format(score), 'log loss:', '{0:.3f}'.format(log_loss))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "score: 0.791 log loss: 0.463\n"
       ]
      }
     ],
     "prompt_number": 293
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "relevant_rsids = {'rs7279445', 'rs5760410', 'rs1801394', 'rs13120400', 'rs4673993', 'rs548234'}\n",
      "\n",
      "patient_ids = list()\n",
      "patients = list()\n",
      "\n",
      "# Load clinical data\n",
      "line_number = 1\n",
      "for line in open('rheumatoid-arthritis/raw_final/TestData_Cov_Release.txt'):\n",
      "#for line in open('rheumatoid-arthritis/raw_training/TrainingData_PhenoCov_Release.txt'):\n",
      "    if line_number == 1: \n",
      "        column_names = line.strip().split(' ') \n",
      "    else:\n",
      "        patient_data = dict(zip(column_names, line.strip().split(' '))) # column_name: value  \n",
      "        patient_ids.append(patient_data['ID'])\n",
      "        \n",
      "        # filter values to only contain relevant information for training/using the classifier\n",
      "        patient_data = { key: tryfloat(patient_data[key]) for key in {'Mtx', 'Drug', 'baselineDAS', 'Gender'}}\n",
      "        if patient_data['Drug'] in ['golimumab', 'certolizumab']:\n",
      "            print('Note: Encountered drug not included in training set, assuming equivalence to etanercept')\n",
      "            patient_data['Drug'] = 'etanercept'\n",
      "        patients.append(patient_data)\n",
      "    line_number += 1\n",
      "\n",
      "# Load dosage data\n",
      "for file_name in glob.glob('rheumatoid-arthritis/raw_final/*.dos'):\n",
      "# for file_name in glob.glob('rheumatoid-arthritis/raw_training/*.dos'):\n",
      "    print('Loading', file_name)\n",
      "    with open(file_name) as f:\n",
      "        for line in f:\n",
      "            i += 1\n",
      "            for rsid in relevant_rsids:\n",
      "                if rsid in line:\n",
      "                    genetic_data_line = line.strip().split(' ')\n",
      "                    rsid = genetic_data_line[1]\n",
      "                    dosage_data = genetic_data_line[6:]\n",
      "                    if len(dosage_data) == len(patients):\n",
      "                        for i, dosage in enumerate(dosage_data):\n",
      "                            patients[i][rsid] = tryfloat(dosage)\n",
      "                    else:\n",
      "                        print('Error: number of SNP variants found (' + str(len(dosage_data)) + ') does not equal number of patients (' + str(len(patients)) + ')')\n",
      "print('Finished loading.')\n",
      "\n",
      "for patient in patients:\n",
      "    patient['methotroxate_score'] = patient['Mtx'] * (patient['rs4673993'] + patient['rs7279445'] + patient['rs1801394'] + patient['rs5760410'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Note: Encountered drug not included in training set, assuming equivalence to etanercept\n",
        "Loading rheumatoid-arthritis/raw_final\\Testdata_chr1.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr10.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr11.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr12.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr13.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr14.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr15.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr16.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr17.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr18.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr19.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr2.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr20.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr21.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr22.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr3.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr4.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr5.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr6.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr7.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr8.dos\n",
        "Loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rheumatoid-arthritis/raw_final\\Testdata_chr9.dos\n",
        "Finished loading."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 301
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert data dictionary to matrix\n",
      "vec = DictVectorizer()\n",
      "patients_vectorized = vec.fit_transform(patients).toarray()\n",
      "\n",
      "# take care of NaNs\n",
      "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
      "imp.fit(patients_vectorized)\n",
      "patients_vectorized = imp.transform(patients_vectorized)\n",
      "\n",
      "print(\"Features:\\n\")\n",
      "print(vec.get_feature_names())\n",
      "print(\"\\nExample data matrices:\\n\")\n",
      "print(patients_vectorized[0:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Features:\n",
        "\n",
        "['Drug', 'Drug=adalimumab', 'Drug=etanercept', 'Drug=infliximab', 'Gender', 'Mtx', 'baselineDAS', 'methotroxate_score', 'rs13120400', 'rs1801394', 'rs4673993', 'rs548234', 'rs5760410', 'rs7279445']\n",
        "\n",
        "Example data matrices:\n",
        "\n",
        "[[  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
        "    0.00000000e+00   0.00000000e+00   3.60480165e+00   0.00000000e+00\n",
        "    1.10000000e-02   2.00000000e+00   9.98000000e-01   0.00000000e+00\n",
        "    9.87000000e-01   2.00000000e+00]\n",
        " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
        "    1.00000000e+00   1.00000000e+00   2.92673159e+00   4.02700000e+00\n",
        "    3.00000000e-03   2.00000000e+00   2.00000000e-03   1.00000000e+00\n",
        "    1.02500000e+00   1.00000000e+00]\n",
        " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
        "    1.00000000e+00   0.00000000e+00   5.30790806e+00   0.00000000e+00\n",
        "    9.97000000e-01   0.00000000e+00   9.98000000e-01   1.00000000e+00\n",
        "    1.02400000e+00   1.00000000e+00]\n",
        " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
        "    1.00000000e+00   0.00000000e+00   4.11075211e+00   0.00000000e+00\n",
        "    2.20000000e-02   2.00000000e+00   9.98000000e-01   1.00000000e+00\n",
        "    1.83800000e+00   0.00000000e+00]\n",
        " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
        "    1.00000000e+00   0.00000000e+00   4.05278683e+00   0.00000000e+00\n",
        "    1.00000000e+00   2.00000000e+00   2.00000000e-03   1.00000000e+00\n",
        "    9.96000000e-01   2.00000000e+00]]\n"
       ]
      }
     ],
     "prompt_number": 302
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predicted_probabilities = clf.predict_proba(patients_vectorized)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 303
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('rheumatoid-arthritis/analysis/prediction_final.txt', 'w') as output_file:\n",
      "    print('ID,Response.nonResp', file = output_file)\n",
      "    for i, patient_id in enumerate(patient_ids):\n",
      "        print(patient_id + ',' + str(round(predicted_probabilities[i][1],4)), file = output_file)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 307
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}